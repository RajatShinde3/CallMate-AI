import streamlit as st
import requests, tempfile, av
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import speech_recognition as sr
from pydub import AudioSegment

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FFmpeg path for pydub (change if your path differs)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AudioSegment.converter = (
    r"C:\\Users\\rajat\\Downloads\\Compressed\\ffmpeg-7.1.1-essentials_build"
    r"\\ffmpeg-7.1.1-essentials_build\\bin\\ffmpeg.exe"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit Page Config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="CallMate AI", page_icon="ğŸ“", layout="centered")

st.markdown(
    """
    <h1 style='text-align:center;font-size:38px;margin-bottom:4px'>ğŸ“ CallMate AI</h1>
    <h4 style='text-align:center;color:gray;margin-top:0'>Your realâ€‘time AIâ€‘powered call assistant</h4>
    <hr style='margin-top:8px;margin-bottom:18px'>
    """,
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Initialise Session State
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for k in (
    "last_resp", "last_input", "consent_given", "consent_sent",
    "conversation", "voice_transcript",
):
    if k not in st.session_state:
        st.session_state[k] = [] if k == "conversation" else None

# Audio buffer setup
if "audio_buffer" not in st.session_state:
    st.session_state.audio_buffer = bytearray()

CALL_ID = "demo-call-123"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Consent Checkbox
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.session_state.consent_given = st.checkbox(
    "I consent to AIâ€‘assisted responses being generated and stored."
)

# ------------------------------------------------------------------
# Conversation history bubbles
# ------------------------------------------------------------------
if st.session_state.conversation:
    st.markdown("### ğŸ—’ï¸ Conversation so far")
    for i, line in enumerate(st.session_state.conversation, 1):
        st.markdown(
            f"<div style='background:#F2F6FF;padding:8px;border-radius:10px;margin-bottom:4px'><b>User {i}:</b> {line}</div>",
            unsafe_allow_html=True,
        )
    st.divider()

# ------------------------------------------------------------------
# ğŸ™ï¸ Voice Mode
# ------------------------------------------------------------------
st.markdown("### ğŸ™ï¸ Voice Mode (optional)")

class AudioProcessor:
    def recv(self, frame: av.AudioFrame):
        audio_bytes = frame.to_ndarray().tobytes()
        if audio_bytes:
            st.session_state.audio_buffer.extend(audio_bytes)
            print("ğŸ”Š Audio frame received â€”", len(audio_bytes), "bytes")
        return frame

webrtc_streamer(
    key="voice-mode",
    mode=WebRtcMode.SENDONLY,
    media_stream_constraints={"video": False, "audio": True},
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    audio_receiver_size=1024,
    audio_frame_callback=AudioProcessor().recv,
)

st.caption(f"ğŸ›ï¸ Bytes captured: {len(st.session_state.audio_buffer)}")

# ------------------------------------------------------------------
# Transcribe button
# ------------------------------------------------------------------
if st.button("ğŸ¤ Transcribe Audio"):
    if len(st.session_state.audio_buffer) == 0:
        st.warning("ğŸ™ï¸ No audio yet â€” click â–¶ï¸, speak for 2â€‘3â€¯s, then try again.")
    else:
        with st.spinner("Transcribingâ€¦"):
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                tmp.write(st.session_state.audio_buffer)
                wav_path = tmp.name

            st.session_state.audio_buffer = bytearray()

            recognizer = sr.Recognizer()
            with sr.AudioFile(wav_path) as src:
                audio = recognizer.record(src)
                try:
                    transcript = recognizer.recognize_google(audio)
                    st.session_state.voice_transcript = transcript
                    st.success(f"ğŸ—£ï¸ You said: {transcript}")
                except sr.UnknownValueError:
                    st.error("Couldnâ€™t understand the audio.")
                except sr.RequestError as e:
                    st.error(f"Speechâ€‘toâ€‘text error: {e}")

# ------------------------------------------------------------------
# Text input (prefilled with transcript)
# ------------------------------------------------------------------
prefill = st.session_state.voice_transcript or ""
text_input = st.text_input(
    "ğŸ’¬ Customer says:",
    value=prefill,
    placeholder="e.g., I still havenâ€™t received my refundâ€¦",
    max_chars=500,
)

btn_disabled = (not st.session_state.consent_given) or (len(text_input.strip()) == 0)
if not st.session_state.consent_given:
    st.caption("âš ï¸ Tick the consent box to enable suggestions.")
elif len(text_input.strip()) == 0:
    st.caption("âš ï¸ Type or speak a message.")

# ------------------------------------------------------------------
# Submit to backend
# ------------------------------------------------------------------
if st.button("ğŸ” Get AI Suggestion", disabled=btn_disabled):
    try:
        if not st.session_state.consent_sent:
            requests.post(
                "http://localhost:8000/consent",
                params={"call_id": CALL_ID, "consent": True},
                timeout=5,
            )
            st.session_state.consent_sent = True

        with st.spinner("ğŸ’¡ Thinkingâ€¦"):
            resp = requests.post(
                "http://localhost:8000/suggest",
                json={"text": text_input, "call_id": CALL_ID},
                timeout=15,
            )

        st.session_state.last_resp = resp.json()
        st.session_state.last_input = text_input
        st.session_state.conversation.append(text_input)
        st.session_state.voice_transcript = ""

    except requests.exceptions.RequestException as e:
        st.error(f"âŒ Backend error: {e}")
        st.stop()

# ------------------------------------------------------------------
# Display backend response
# ------------------------------------------------------------------
data = st.session_state.last_resp
if data and "suggestion" in data:
    st.markdown("### ğŸ’¡ Suggested Agent Reply")
    st.success(data["suggestion"])

    sent = data.get("sentiment", "neutral")
    col = {"positive": "green", "negative": "red"}.get(sent, "gray")
    emo = {"positive": "ğŸ˜Š", "neutral": "ğŸ˜", "negative": "ğŸ˜ "}.get(sent, "ğŸ˜")
    st.markdown(f"**{emo} Sentiment:** <span style='color:{col}'>{sent.capitalize()}</span>", unsafe_allow_html=True)

    if "confidence" in data:
        c = data["confidence"]
        st.caption(f"ğŸ” Confidence â†’ Sentiment {int(c['sentiment']*100)}% | Knowledge {int(c['knowledge']*100)}% | Compliance {int(c['compliance']*100)}%")

    if data.get("compliance") == "flagged":
        st.warning("âš ï¸ Compliance Alert: sensitive terms detected")
    else:
        st.markdown("<span style='color:green'>âœ” Compliance: clean</span>", unsafe_allow_html=True)

    st.markdown(f"ğŸš¨ **Escalation:** {data.get('escalation','N/A')}")
    st.caption(f"â±ï¸ LLM latency: {data.get('latency_ms', 0)} ms")

    if data.get("pii_redacted"):
        st.markdown("ğŸ”’ _Sensitive data masked_")

    st.divider()

    st.markdown("### ğŸ—£ï¸ Was this suggestion helpful?")
    c1, c2 = st.columns(2)

    def send_feedback(helpful: bool):
        requests.post(
            "http://localhost:8000/feedback",
            json={"call_id": CALL_ID, "text": st.session_state.last_input, "helpful": helpful},
            timeout=5,
        )

    if c1.button("ğŸ‘ Yes"):
        send_feedback(True)
        st.success("Thanks for your feedback!")
    if c2.button("ğŸ‘ No"):
        send_feedback(False)
        st.warning("Thanks, weâ€™ll improve!")

    summary = requests.get("http://localhost:8000/feedback/summary", timeout=5).json()
    st.markdown(f"**ğŸ§® Feedback so far â†’** ğŸ‘ {summary['ğŸ‘']} | ğŸ‘ {summary['ğŸ‘']}", unsafe_allow_html=True)

    st.divider()

    if st.button("ğŸ“‘ End Call & Generate Report"):
        rep = requests.get(f"http://localhost:8000/summary/{CALL_ID}", timeout=10).json()
        st.markdown("## ğŸ“‘ Post-Call Report")
        st.write(rep["summary"])
        st.markdown(
            f"**Overall sentiment:** {rep['sentiment_overall'].capitalize()}   \n"
            f"**Compliance:** {rep['compliance_overall']}   \n"
            f"**Escalation:** {rep['escalation']}"
        )
        with st.expander("ğŸ—’ï¸ Full conversation context"):
            for line in rep["utterances"]:
                st.write("â€¢", line)

    with st.expander("ğŸ” Raw backend response"):
        st.json(data)
