
# ðŸ“ž CallMate AI â€“ Real-time GenAI Call Assistant

<p align="center">
  <img src="https://img.shields.io/badge/Streamlit-1.46-orange?logo=streamlit" />
  <img src="https://img.shields.io/badge/FastAPI-0.110-green?logo=fastapi" />
  <img src="https://img.shields.io/badge/GenAI-powered-blueviolet?logo=openai" />
</p>

> A voice-enabled, explainable, and compliant customer support assistant powered by multi-agent LLM architecture â€” built for speed, trust, and clarity.

---

## ðŸš€ Overview

CallMate AI supports customer agents during high-pressure conversations by providing real-time GenAI suggestions that are:

- âœ… Sentiment-aware  
- âœ… Policy-compliant  
- âœ… Confidence-transparent  
- âœ… Voice and text driven  

---

## ðŸŽ¯ Key Features

| âœ… Feature                | ðŸ’¡ Description                                                           |
|--------------------------|---------------------------------------------------------------------------|
| ðŸŽ™ï¸ Voice & Text Input    | Upload `.wav` audio or type input manually in Streamlit UI               |
| ðŸ¤– Multi-Agent Inference | Sentiment, Compliance, and Knowledge agents working in parallel           |
| ðŸ“Š Confidence Display    | Transparent scoring for all responses                                     |
| âš ï¸ PII Redaction         | Detects and masks sensitive info (email, card numbers, etc.)              |
| ðŸ“‘ Post-call Summary     | Automatically generated call recap with key insights                     |
| ðŸ—³ï¸ Feedback Logging      | User feedback stored in local SQLite database                             |
| â˜ï¸ Cloud-Ready           | Deployable on AWS EC2, Bedrock-compatible architecture                    |

---

## ðŸ§  Architecture

```mermaid
graph TD
    U[ðŸ‘¤ User (Voice/Text)] --> R(ðŸ”’ Redactor)
    R --> SA(Sentiment Agent)
    R --> KA(Knowledge Agent)
    R --> CA(Compliance Agent)
    SA --> ESC(ðŸ”º Escalation)
    CA --> ESC
    KA --> UI[ðŸ’¬ Streamlit UI]
    ESC --> UI
```

---

## ðŸ–¥ï¸ Live Demos & Docs

| Type            | Link                                                                                           |
|-----------------|------------------------------------------------------------------------------------------------|
| ðŸ–¥ï¸ Live EC2 Demo | [http://ec2-XX-XX-XX.compute.amazonaws.com:8501](http://ec2-XX-XX-XX.compute.amazonaws.com:8501) |
| ðŸ§ª Swagger Docs   | [http://localhost:8000/docs](http://localhost:8000/docs)                                       |
| ðŸŽ¥ Demo Video    | [https://youtu.be/YOUR_VIDEO_ID](https://youtu.be/YOUR_VIDEO_ID)                               |

---

## ðŸ§° Tech Stack

| Layer    | Tools Used                       |
|----------|----------------------------------|
| UI       | Streamlit, HTML, `streamlit-webrtc` (optional) |
| Backend  | FastAPI, asyncio, Pydantic       |
| Audio    | SpeechRecognition, Pydub, FFmpeg |
| Storage  | SQLite for feedback              |
| Infra    | AWS EC2, localhost, Bedrock-ready |

---

## ðŸ“Š Performance Metrics

| Metric                       | Value        |
|-----------------------------|--------------|
| Avg. LLM Suggestion Latency | ~320 ms      |
| PII Redaction Accuracy      | 100%         |
| Sentiment Detection Accuracy| ~92% (sample)|
| Feedback Received           | ðŸ‘ 5â€ƒ ðŸ‘Ž 1     |

---

## âš™ï¸ Getting Started

### 1. Clone the repo
```bash
git clone https://github.com/RajatShinde/callmate-ai.git
cd callmate-ai
```

### 2. Set up virtual environment
```bash
python -m venv .venv
source .venv/bin/activate       # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Set FFmpeg path (required for audio)
Download FFmpeg from: [https://www.gyan.dev/ffmpeg/builds/](https://www.gyan.dev/ffmpeg/builds/)

Set this in your code before using `AudioSegment`:
```python
from pydub import AudioSegment
AudioSegment.converter = "C:/ffmpeg/bin/ffmpeg.exe"  # Update path accordingly
```

---

## ðŸŒ Deployment (AWS EC2)

1. Launch EC2 instance (Amazon Linux / Ubuntu)
2. Open inbound ports: **8000** (FastAPI), **8501** (Streamlit)
3. SSH into server & clone this repo
4. Run backend:
```bash
uvicorn backend.main:app --host 0.0.0.0 --port 8000
```
5. Run frontend:
```bash
streamlit run frontend/app.py --server.port 8501
```
6. Access via public DNS in browser

---

## ðŸ“ Project Structure

```
callmate-ai/
â”‚
â”œâ”€â”€ frontend/              # Streamlit app (app.py)
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â”œâ”€â”€ agents.py          # AI agents: Sentiment, Knowledge, Compliance
â”‚   â”œâ”€â”€ feedback_db.py     # Feedback database (SQLite)
â”‚   â””â”€â”€ pii_redactor.py    # PII redaction logic
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # You're here!
```

---

## ðŸ”® Future Roadmap

- ðŸ”„ Integrate Amazon Bedrock (Titan or Claude)
- ðŸ“Š Add real-time charts for confidence drift
- ðŸŽ™ï¸ Use Amazon Transcribe for improved voice accuracy
- ðŸ’¾ Scale logs to DynamoDB
- ðŸ” Add role-based authentication for agents

---

## ðŸ† Why CallMate AI?

| ðŸ’¥ Factor            | âœ… Strength                                    |
|----------------------|------------------------------------------------|
| Real-time UX         | Fast LLM response, voice or text input         |
| Trust & Transparency | Clear confidence %, latency, PII masking       |
| Contact Center Ready | Built for CSAT, AHT, escalation tracking       |
| Modular Design       | Easy to plug in new models or services         |
| Developer Friendly   | Pythonic, FastAPI/Streamlit, clean code        |

---

## ðŸ“œ License

**MIT License** â€” Free for personal, academic, and commercial use.

---

## ðŸ“¬ Contact

- ðŸ“§ Email: [rajatshinde100@gmail.com](mailto:rajatshinde100@gmail.com)  
- ðŸ”— [LinkedIn](https://www.linkedin.com/in/YOUR_LINKEDIN)  
- ðŸ”— [GitHub](https://github.com/RajatShinde)

---

> âš ï¸ DO NOT commit `.env` or sensitive data.
> This repo includes a `.env.example` to help set up locally.

---
